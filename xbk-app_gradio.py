# app_gradio.py
import gradio as gr
import sys
from fastapi import FastAPI
import uvicorn
from rag_service import load_chroma_collection, rag_query

# Load collection khi khá»Ÿi Ä‘á»™ng
try:
    _ = load_chroma_collection()
    print("[Gradio App] ChromaDB collection Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng.")
except Exception as e:
    print(f"[Gradio App] Lá»—i nghiÃªm trá»ng khi táº£i ChromaDB: {e}")
    print("[Gradio App] á»¨ng dá»¥ng sáº½ khÃ´ng hoáº¡t Ä‘á»™ng náº¿u khÃ´ng cÃ³ cÆ¡ sá»Ÿ dá»¯ liá»‡u. Vui lÃ²ng kiá»ƒm tra logs.")
    sys.exit(1)

NO_INFO_ANSWER = "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin Ä‘á»§ chi tiáº¿t trong cÃ¡c Kinh Ä‘Ã£ Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i nÃ y."
RAG_ERROR_ANSWER_PREFIX = "Xin lá»—i, cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ yÃªu cáº§u cá»§a báº¡n:"

def query_and_answer(user_input):
    if not user_input.strip():
        return "Vui lÃ²ng nháº­p cÃ¢u há»i."

    try:
        results, answer = rag_query(user_input)

        is_no_info_response = (answer == NO_INFO_ANSWER)
        is_rag_error_response = answer.startswith(RAG_ERROR_ANSWER_PREFIX)

        final_output = f"ğŸ§  **CÃ¢u tráº£ lá»i tá»« AI:**\n{answer}\n\n"

        if not is_no_info_response and not is_rag_error_response:
            metadatas = results["metadatas"][0] if results and results["metadatas"] else []
            unique_sources = set()

            if metadatas:
                for metadata in metadatas:
                    bo = metadata.get('Bá»™')
                    ten_kinh_day_du = metadata.get('TÃªn Kinh Äáº§y Äá»§')
                    viet_dich = metadata.get('Viá»‡t Dá»‹ch')
                    so_pham = metadata.get('Sá»‘ Pháº©m')
                    ten_kinh_nho = metadata.get('TÃªn Kinh Nhá»')

                    source_info_parts = []
                    if bo: source_info_parts.append(f"Bá»™: {bo}")
                    if ten_kinh_day_du: source_info_parts.append(f"Kinh: {ten_kinh_day_du}")
                    if viet_dich: source_info_parts.append(f"Dá»‹ch: {viet_dich}")
                    if so_pham: source_info_parts.append(f"Pháº§n: {so_pham}")
                    if ten_kinh_nho: source_info_parts.append(f"Kinh: {ten_kinh_nho}")

                    source_info = ", ".join(filter(None, source_info_parts))
                    if source_info:
                        unique_sources.add(source_info)

            sorted_unique_sources = sorted(list(unique_sources))

            if sorted_unique_sources:
                context_text = "\n".join([f"_ {s}_" for s in sorted_unique_sources])
                final_output += f"ğŸ“š **Ngá»¯ cáº£nh liÃªn quan tá»«:**\n{context_text}"
            else:
                final_output += "ğŸ“š **KhÃ´ng tÃ¬m tháº¥y ngá»¯ cáº£nh liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.**"
        else:
            final_output += "ğŸ“š **KhÃ´ng cÃ³ ngá»¯ cáº£nh liÃªn quan Ä‘Æ°á»£c hiá»ƒn thá»‹ do thÃ´ng tin khÃ´ng Ä‘á»§ hoáº·c lá»—i.**"

        return final_output
    except Exception as e:
        return f"Lá»—i khi xá»­ lÃ½: {str(e)}"

# Táº¡o giao diá»‡n Gradio
iface = gr.Interface(
    fn=query_and_answer,
    inputs=gr.Textbox(label="Nháº­p cÃ¢u há»i vá» Kinh Ä‘iá»ƒn", placeholder="VÃ­ dá»¥: NÄƒm sanh phÃ¡p lÃ  gÃ¬?", lines=2),
    outputs=gr.Textbox(label="Káº¿t quáº£", lines=10),
    title="ğŸ“œ Tra cá»©u Kinh Ä‘iá»ƒn Pháº­t giÃ¡o (RAG + Chatling AI)",
    description="Há»‡ thá»‘ng sá»­ dá»¥ng ChromaDB + Chatling AI Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i tá»« dá»¯ liá»‡u Kinh Pháº­t. Vui lÃ²ng Ä‘á»£i chÃºt khi á»©ng dá»¥ng khá»Ÿi Ä‘á»™ng láº§n Ä‘áº§u.",
    theme="soft"
)

# Táº¡o FastAPI app vÃ  mount Gradio app vÃ o
app = FastAPI()
gradio_app = gr.routes.App.create_app(iface)
gradio_app.blocks.config["dev_mode"] = False  # Táº¯t dev_mode Ä‘á»ƒ trÃ¡nh reload loop
app.mount("/", gradio_app)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=7860)
